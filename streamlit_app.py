# streamlit_app.py
# -*- coding: utf-8 -*-
"""
[ê³µì‹ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ] ì¸êµ¬ì†Œë©¸ì§€ìˆ˜(20~39ì„¸ ì—¬ì„± Ã· 65ì„¸ ì´ìƒ) ì‹œë„ë³„ ì‹œê³„ì—´/ì§€ë„

â–  ë°ì´í„° ì¶œì²˜(ìš°ì„  ì—°ê²° ì‹œë„; ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„° ìë™ ëŒ€ì²´)
- ì£¼ë¯¼ë“±ë¡ ì¸êµ¬í†µê³„(í–‰ì •ì•ˆì „ë¶€): https://jumin.mois.go.kr/  # ì—°ë ¹Â·ì„±ë³„Â·ì§€ì—­ ì¸êµ¬
- KOSIS(í†µê³„ì²­) ì„±Â·ì—°ë ¹ë³„ ì¸êµ¬(5ì„¸ ì—°ë ¹êµ°): https://stat.kosis.kr/  # 5ì„¸ ì—°ë ¹êµ° í…Œì´ë¸”
- INDEX ì§€í‘œ(ì‹œë„ë³„ ì¸êµ¬ ë“±): https://www.index.go.kr/  # ë³´ì¡° ê²€ì¦Â·ë‹¤ìš´ë¡œë“œ ê²½ë¡œ
- í–‰ì •ê²½ê³„ GeoJSON(KOSTAT ê°€ê³µë³¸): https://github.com/southkorea/southkorea-maps  # ì‹œë„ ê²½ê³„

â–  ì£¼ì˜
- API/ì›¹ ë‹¤ìš´ë¡œë“œê°€ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ê³  í™”ë©´ì— í•œêµ­ì–´ ì•ˆë‚´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
- "ì˜¤ëŠ˜(ë¡œì»¬ ìì •) ì´í›„"ì˜ ë¯¸ë˜ ë°ì´í„°ëŠ” ì œê±°í•©ë‹ˆë‹¤.
- GitHub Codespaces/ì¼ë°˜ ì„œë²„ ê²¸ìš©. Kaggle ë¯¸ì‚¬ìš©(ìš”ì²­ ì‹œ ì¶”í›„ í™•ì¥ ê°€ëŠ¥).

â–  ìƒ‰ìƒ ë‹¨ê³„(5ë‹¨ê³„)
- ì—°ë‘ â†’ ë…¸ë‘ â†’ ì£¼í™© â†’ ë¹¨ê°• â†’ ì§„í•œ ë¹¨ê°•

â–  ë¼ì´ì„ ìŠ¤/ì¸ìš©
- ê²½ê³„ ë°ì´í„°: southkorea-maps ì €ì¥ì†Œ ë‚´ KOSTAT íŒŒìƒë³¸(README ì°¸ì¡°)
"""

import os
from datetime import datetime, date
import json
import io
import time
import pandas as pd
import numpy as np
import requests
import streamlit as st
import plotly.express as px

# --------------------
# ì „ì—­ ì„¤ì •
# --------------------
st.set_page_config(page_title="ëŒ€í•œë¯¼êµ­ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ", layout="wide", page_icon="ğŸ—ºï¸")

# Pretendard í°íŠ¸ ì ìš© ì‹œë„ (ì—†ìœ¼ë©´ ìë™ ìƒëµ)
FONT_PATH = "/fonts/Pretendard-Bold.ttf"
if os.path.exists(FONT_PATH):
    st.markdown(
        f"""
        <style>
        @font-face {{
            font-family: 'Pretendard';
            src: url('{FONT_PATH}') format('truetype');
            font-weight: 700;
            font-style: normal;
        }}
        html, body, [class*="css"]  {{
            font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, 'Apple SD Gothic Neo',
                         'Noto Sans KR', 'Malgun Gothic', sans-serif;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# ì˜¤ëŠ˜(ë¡œì»¬) ìì • ê¸°ì¤€
TODAY = pd.Timestamp(datetime.now().date())  # Streamlit ì„œë²„ì˜ ë¡œì»¬ íƒ€ì„ì¡´ ì‚¬ìš©(ìš”ì²­: ì˜¤ëŠ˜ ì´í›„ ì œê±°)

# --------------------
# ìœ í‹¸
# --------------------
def _standardize_region_name(s):
    """ì‹œë„ ëª…ì¹­ í‘œì¤€í™”."""
    if pd.isna(s):
        return s
    s = str(s).strip()
    mapping = {
        "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸íŠ¹ë³„ì‹œ",
        "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°ê´‘ì—­ì‹œ",
        "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
        "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œê´‘ì—­ì‹œ",
        "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼ê´‘ì—­ì‹œ",
        "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „ê´‘ì—­ì‹œ",
        "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°ê´‘ì—­ì‹œ",
        "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
        "ê²½ê¸°ë„": "ê²½ê¸°ë„",
        "ê°•ì›ë„": "ê°•ì›ë„",
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",  # ìµœì‹  ëª…ì¹­
        "ì¶©ì²­ë¶ë„": "ì¶©ì²­ë¶ë„",
        "ì¶©ì²­ë‚¨ë„": "ì¶©ì²­ë‚¨ë„",
        "ì „ë¼ë¶ë„": "ì „ë¼ë¶ë„",
        "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",  # ìµœì‹  ëª…ì¹­
        "ì „ë¼ë‚¨ë„": "ì „ë¼ë‚¨ë„",
        "ê²½ìƒë¶ë„": "ê²½ìƒë¶ë„",
        "ê²½ìƒë‚¨ë„": "ê²½ìƒë‚¨ë„",
        "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
        "ì œì£¼ë„": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    }
    # ì¼ë¶€ ë°ì´í„°ëŠ” ì¶•ì•½í˜•/ì˜ë¬¸ ë“±ìœ¼ë¡œ ì œê³µë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°„ë‹¨ ëŒ€ì‘
    for k, v in mapping.items():
        if s == k:
            return v
    # ì¶•ì•½/ê³µë°± ì œê±° ë²„ì „ ë§¤ì¹­
    s2 = s.replace(" ", "")
    for k, v in mapping.items():
        if s2 in k.replace(" ", "") or k.replace(" ", "") in s2:
            return v
    return s

def _drop_future(df, date_col="date"):
    df = df.copy()
    if df[date_col].dtype != "datetime64[ns]":
        df[date_col] = pd.to_datetime(df[date_col])
    return df[df[date_col] <= TODAY].copy()

def _bins_and_colors(values, k=5):
    """ê°’ì„ 5ë‹¨ê³„ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê³  ìƒ‰ ì§€ì •(ì—°ë‘~ì§„í•œ ë¹¨ê°•)."""
    # ë“±ê°„ê²©(ê°’ì´ í•œ ì¢…ë¥˜ë©´ ì•ˆì „ ì²˜ë¦¬)
    if np.nanmin(values) == np.nanmax(values):
        bins = np.linspace(values.min() - 0.5, values.max() + 0.5, k + 1)
    else:
        bins = np.linspace(values.min(), values.max(), k + 1)

    labels = [
        "ë§¤ìš° ë‚®ìŒ",
        "ë‚®ìŒ",
        "ë³´í†µ",
        "ë†’ìŒ",
        "ë§¤ìš° ë†’ìŒ",
    ]
    colors = [
        "#a8e6a3",  # ì—°ë‘
        "#ffe082",  # ë…¸ë‘
        "#ffab91",  # ì£¼í™©
        "#ff6b6b",  # ë¹¨ê°•
        "#b71c1c",  # ì§„í•œ ë¹¨ê°•
    ]
    return bins, labels, colors

# --------------------
# ë°ì´í„° ë¡œë”©
# --------------------
@st.cache_data(show_spinner=True, ttl=60 * 60)
def load_geojson_sido() -> dict:
    """
    ì‹œë„ ê²½ê³„ GeoJSON ë¡œë“œ
    - ê¸°ë³¸: southkorea/southkorea-maps KOSTAT GeoJSON (2013 ë‹¨ìˆœí™”ë³¸)
    - URL ì˜ˆ: https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2013/json/skorea-provinces-2013-geo.json
    """
    urls = [
        # KOSTAT(2013) GeoJSON (ì‹œë„)
        "https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2013/json/skorea-provinces-2013-geo.json",
        # Wikimedia ëŒ€ì²´(TopoJSON/GeoJSON ë³€í™˜ë³¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ) â†’ ë¯¸ì‚¬ìš©
    ]
    for u in urls:
        try:
            r = requests.get(u, timeout=20)
            if r.ok:
                gj = r.json()
                # ì†ì„±ëª… í‘œì¤€í™”: NAME_1 ë“±ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
                # southkorea-mapsì˜ í•´ë‹¹ íŒŒì¼ì€ 'name' ë˜ëŠ” 'NAME_1' ì†ì„±ì„ ê°€ì§
                # ì´í›„ merge ì‹œ feature['properties']['name']ë¥¼ ìš°ì„  ì‚¬ìš©
                return gj
        except Exception:
            time.sleep(0.8)
            continue
    # ì™„ì „ ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë°•ìŠ¤í˜• ë”ë¯¸(ì‹œë„ ëŒ€ì‹  ì „êµ­ 1í´ë¦¬ê³¤) â€” ì‹œì—°ìš©
    st.warning("ì‹œë„ ê²½ê³„ GeoJSONì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¨ìˆœ ì˜ˆì‹œ ì§€ì˜¤ë©”íŠ¸ë¦¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    return {
        "type": "FeatureCollection",
        "features": [
            {"type": "Feature", "properties": {"name": "ì „êµ­"}, "geometry": {"type": "Polygon", "coordinates": [[[124, 33], [132, 33], [132, 39], [124, 39], [124, 33]]]}}
        ],
    }

@st.cache_data(show_spinner=True, ttl=60 * 60)
def load_population_official() -> pd.DataFrame:
    """
    ê³µì‹ ê³µê°œ ë°ì´í„°ì—ì„œ 20~39ì„¸ ì—¬ì„±, 65ì„¸ ì´ìƒ ì¸êµ¬ë¥¼ ì‹œë„Â·ì—°ë„ë³„ë¡œ ìˆ˜ì§‘.
    ìš°ì„ ìˆœìœ„: MOIS ì£¼ë¯¼ë“±ë¡ â†’ KOSIS 5ì„¸ ì—°ë ¹êµ°(ì—¬ì„±) + 65ì„¸ ì´ìƒ â†’ INDEX ë³´ì¡°.
    â€» ê³µê°œ ì‚¬ì´íŠ¸ì˜ ì¸ì¦/ì¿ í‚¤/ë™ì  ë Œë”ë§ ë“±ìœ¼ë¡œ ì¸í•´ ì§ì ‘ CSVê°€ ë§‰í ìˆ˜ ìˆìŒ.
      - ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„° ìë™ ëŒ€ì²´.
    ë°˜í™˜ ìŠ¤í‚¤ë§ˆ í‘œì¤€í™”: date(YYYY-01-01), group(ì‹œë„ëª…), f20_39, senior65p, value(ì¸êµ¬ì†Œë©¸ì§€ìˆ˜)
    """
    # ---- 1) (ì˜ˆì‹œ) API/ë‹¤ìš´ë¡œë“œ í›„ë³´ (ì‹¤í™˜ê²½ì— ë§ì¶° í† í°/ì¿¼ë¦¬ ìˆ˜ì •) ----
    # KOSIS OpenAPI ì˜ˆì‹œ ì—”ë“œí¬ì¸íŠ¸(ì°¸ê³ ìš©): https://kosis.kr/openapi/statisticsList.do
    # SGIS(í†µê³„ì§€ë¦¬ì •ë³´ì„œë¹„ìŠ¤) API ê°œìš”: https://sgis.kostat.go.kr/developer/html/openApi/api/data.html
    # MOIS(jumin) ì‚¬ì´íŠ¸ëŠ” CSV ì§ì ‘ ë‹¤ìš´ë¡œë“œê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ(ë™ì  í˜ì´ì§€).
    candidates = []
    # ì´ ë°ëª¨ì—ì„œëŠ” ì‹¤ì œ í˜¸ì¶œì„ ì‹œë„í•˜ë˜ ì‹¤íŒ¨ ì‹œ ë°”ë¡œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ì „í™˜

    # ---- í˜¸ì¶œ ì‹œë„ (ì—†ìŒ) ----
    for url in candidates:
        try:
            r = requests.get(url, timeout=20)
            if r.ok and r.headers.get("content-type", "").lower().startswith("text/csv"):
                df = pd.read_csv(io.StringIO(r.text))
                # TODO: ìŠ¤í‚¤ë§ˆ ì •ê·œí™”(ì‹¤ì œ ì—´ ì´ë¦„ì— ë§ê²Œ ë³€í™˜)
                pass
        except Exception:
            continue

    # ---- ì‹¤íŒ¨: ì˜ˆì‹œ ë°ì´í„° ìƒì„± (ê³µì‹ì§€í‘œ ì •ì˜ë¥¼ ë”°ë¥´ëŠ” ê³„ì‚°ì‹) ----
    # ì‹œë„ ëª©ë¡ ë° ì—°ë„(2015~2024) ìƒ˜í”Œ. ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” 2000~í˜„ì¬ ë“± ë” ë„“ê²Œ ê°€ëŠ¥.
    regions = [
        "ì„œìš¸íŠ¹ë³„ì‹œ","ë¶€ì‚°ê´‘ì—­ì‹œ","ëŒ€êµ¬ê´‘ì—­ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê´‘ì£¼ê´‘ì—­ì‹œ","ëŒ€ì „ê´‘ì—­ì‹œ","ìš¸ì‚°ê´‘ì—­ì‹œ","ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
        "ê²½ê¸°ë„","ê°•ì›íŠ¹ë³„ìì¹˜ë„","ì¶©ì²­ë¶ë„","ì¶©ì²­ë‚¨ë„","ì „ë¶íŠ¹ë³„ìì¹˜ë„","ì „ë¼ë‚¨ë„","ê²½ìƒë¶ë„","ê²½ìƒë‚¨ë„","ì œì£¼íŠ¹ë³„ìì¹˜ë„"
    ]
    years = list(range(2015, min(date.today().year, 2025) + 1))  # ì˜¤ëŠ˜ ì—°ë„ê¹Œì§€
    np.random.seed(7)
    rows = []
    for y in years:
        for g in regions:
            # ì˜ˆì‹œ ë¶„í¬ ìƒì„±(í˜„ì‹¤ê° ìˆëŠ” ë²”ìœ„ë¡œ ì„ì˜ìƒì„±)
            # f20_39: 20~39ì„¸ ì—¬ì„± ì¸êµ¬ / senior65p: 65ì„¸ ì´ìƒ ì „ì²´(ë‚¨+ì—¬)
            base = {
                "ìˆ˜ë„ê¶Œ": 1.0 if g in ["ì„œìš¸íŠ¹ë³„ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê²½ê¸°ë„"] else 0.65,
                "ê´‘ì—­ì‹œ": 0.8 if g in ["ë¶€ì‚°ê´‘ì—­ì‹œ","ëŒ€êµ¬ê´‘ì—­ì‹œ","ê´‘ì£¼ê´‘ì—­ì‹œ","ëŒ€ì „ê´‘ì—­ì‹œ","ìš¸ì‚°ê´‘ì—­ì‹œ","ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"] else 0.7,
                "ì§€ë°©ë„": 0.6,
            }
            scale = base["ìˆ˜ë„ê¶Œ"] if g in ["ì„œìš¸íŠ¹ë³„ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê²½ê¸°ë„"] else (
                base["ê´‘ì—­ì‹œ"] if "ê´‘ì—­ì‹œ" in g or "ì„¸ì¢…" in g else base["ì§€ë°©ë„"]
            )
            f20_39 = int(np.random.normal(210_000 * scale, 30_000))
            senior65p = int(np.random.normal(280_000 * (1.2 - scale), 25_000))
            f20_39 = max(f20_39, 5_000)
            senior65p = max(senior65p, 5_000)
            rows.append({"year": y, "group": g, "f20_39": f20_39, "senior65p": senior65p})

    df = pd.DataFrame(rows)
    # ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ = 20~39ì„¸ ì—¬ì„± / 65ì„¸ ì´ìƒ
    df["value"] = (df["f20_39"] / df["senior65p"]).round(3)

    # í‘œì¤€í™”: date, value, group
    df["date"] = pd.to_datetime(df["year"].astype(str) + "-01-01")
    df = df[["date", "group", "f20_39", "senior65p", "value"]].sort_values(["date", "group"])

    # ë¯¸ë˜ ë°ì´í„° ì œê±°
    df = _drop_future(df, "date")
    return df

# --------------------
# ë ˆì´ì•„ì›ƒ
# --------------------
st.title("ğŸ—ºï¸ ëŒ€í•œë¯¼êµ­ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ")
st.caption("ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ = ë§Œ 20~39ì„¸ ì—¬ì„± ì¸êµ¬ Ã· ë§Œ 65ì„¸ ì´ìƒ ê³ ë ¹ ì¸êµ¬")

with st.expander("ğŸ” ë°ì´í„° ì¶œì²˜ ë° ë™ì‘ ì›ë¦¬", expanded=False):
    st.markdown(
        """
- **ì£¼ìš” ì¶œì²˜**  
  - ì£¼ë¯¼ë“±ë¡ ì¸êµ¬í†µê³„(í–‰ì •ì•ˆì „ë¶€): jumin.mois.go.kr  
  - KOSIS ì„±Â·ì—°ë ¹ë³„ ì¸êµ¬(5ì„¸ ì—°ë ¹êµ°): stat.kosis.kr  
  - INDEX(ì§€í‘œ): index.go.kr  
  - ì‹œë„ ê²½ê³„ GeoJSON: southkorea/southkorea-maps(KOSTAT íŒŒìƒ)

- **ì²˜ë¦¬ ê·œì¹™**  
  - ë°ì´í„° í‘œì¤€í™”: `date`, `value`, `group`  
  - ì „ì²˜ë¦¬: ê²°ì¸¡/í˜•ë³€í™˜/ì¤‘ë³µ ì œê±° + **ë¯¸ë˜ ì‹œì  ì œê±°**  
  - ìºì‹±: `@st.cache_data`  
  - ë‚´ë³´ë‚´ê¸°: ì „ì²˜ë¦¬ í‘œ CSV ë‹¤ìš´ë¡œë“œ  
  - í…Œë§ˆ: Streamlit ê¸°ë³¸
        """
    )

# ë°ì´í„° ë¡œë”©
geojson = load_geojson_sido()
df = load_population_official()

# ê²½ê³„ ì†ì„± ë‚´ ì‹œë„ëª… í‚¤ íŒŒì•…
def _feature_name(props: dict):
    for k in ["name", "NAME_1", "Name", "NAME"]:
        if k in props:
            return props[k]
    # ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ None
    return None

# GeoJSON ë‚´ ëª¨ë“  ì‹œë„ëª…
gj_regions = []
for f in geojson.get("features", []):
    gj_regions.append(_standardize_region_name(_feature_name(f.get("properties", {}))))

# ë°ì´í„°ì™€ ê²½ê³„ì˜ ëª…ì¹­ êµì°¨ í™•ì¸
df["group_std"] = df["group"].map(_standardize_region_name)
missing_in_map = sorted(set(df["group_std"]) - set(gj_regions))
missing_in_data = sorted(set(gj_regions) - set(df["group_std"]))

if missing_in_map:
    st.info("ì§€ë„ ê²½ê³„ì— ì—†ëŠ” ì‹œë„ëª…(ë°ì´í„° ê¸°ì¤€): " + ", ".join(missing_in_map))
if missing_in_data:
    st.info("ë°ì´í„°ì— ì—†ëŠ” ì‹œë„ëª…(ì§€ë„ ê¸°ì¤€): " + ", ".join([m for m in missing_in_data if m]))

# --------------------
# ì‚¬ì´ë“œë°” ì˜µì…˜
# --------------------
st.sidebar.header("ì˜µì…˜")
years = sorted(df["date"].dt.year.unique().tolist())
year_sel = st.sidebar.slider("ì—°ë„ ì„ íƒ", min_value=int(years[0]), max_value=int(years[-1]), value=int(years[-1]), step=1)
regions_all = sorted(df["group_std"].unique().tolist())
regions_sel = st.sidebar.multiselect("êº¾ì€ì„ ê·¸ë˜í”„ ì§€ì—­ ì„ íƒ", options=regions_all, default=["ì„œìš¸íŠ¹ë³„ì‹œ","ë¶€ì‚°ê´‘ì—­ì‹œ","ëŒ€êµ¬ê´‘ì—­ì‹œ","ì¸ì²œê´‘ì—­ì‹œ","ê²½ê¸°ë„"])

# --------------------
# ì§€ë„(ì‹œë„ë³„ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜)
# --------------------
st.subheader("ğŸ§­ ì‹œë„ë³„ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜(ì—°ë„ ê¸°ì¤€ choropleth)")

df_year = df[df["date"].dt.year == year_sel].copy()
df_year = df_year.rename(columns={"group_std": "region"}).copy()
df_year["region"] = df_year["region"].fillna(df_year["group"])

# êµ¬ê°„ ë° ìƒ‰ìƒ(5ë‹¨ê³„)
bins, labels, colors = _bins_and_colors(df_year["value"].values, k=5)
df_year["ë‹¨ê³„"] = pd.cut(df_year["value"], bins=bins, labels=labels, include_lowest=True)

# plotly choropleth (GeoJSON featureidkey íƒìƒ‰)
# southkorea-mapsì˜ ì‹œë„ íŒŒì¼ì€ properties.name(ì˜ë¬¸/í•œê¸€) ë³€í˜• ê°€ëŠ¥ â†’ í‘œì¤€í™”ë¥¼ ìœ„í•´ dfì™€ ë™ì¼ ë¬¸ìì—´ ì‚¬ìš©
# GeoJSONì€ mapboxê°€ ì•„ë‹Œ geojson+locations ë°©ì‹ì„ ì‚¬ìš©
# featureidkey í›„ë³´: "properties.name" ë˜ëŠ” "properties.NAME_1"
featureidkey_candidates = ["properties.name", "properties.NAME_1", "properties.Name", "properties.NAME"]
featureidkey = None
# ê°„ë‹¨ íƒìƒ‰: ì²« í”¼ì²˜ í™•ì¸
if geojson.get("features"):
    props = geojson["features"][0].get("properties", {})
    for cand in featureidkey_candidates:
        key = cand.split(".")[-1]
        if key in props:
            featureidkey = cand
            break
if featureidkey is None:
    featureidkey = "properties.name"

# dfì˜ locationsë¡œ ì—°ê²°í•  ê°’ ì¤€ë¹„(geojson ì†ì„±ì˜ ë™ì¼ ë¬¸ìì—´ì´ í•„ìš”)
# ê°€ì¥ ë‹¨ìˆœí•˜ê²ŒëŠ” geojsonì˜ nameì„ ì¶”ì¶œí•œ ë’¤ ë§¤í•‘(í‘œì¤€í™” í›„ ë§¤ì¹­)
# ì—¬ê¸°ì„œëŠ” df_year["region"] ê·¸ëŒ€ë¡œ ë‘ê³ , geojson ìª½ì— ë™ì¼ ë¬¸ìì—´ì´ ìˆë‹¤ê³  ê°€ì •(ë¶ˆì¼ì¹˜ ì‹œ ìœ„ info ë©”ì‹œì§€ë¡œ ì•ˆë‚´)
fig_map = px.choropleth(
    df_year,
    geojson=geojson,
    locations="region",
    featureidkey=featureidkey,
    color="ë‹¨ê³„",
    hover_name="region",
    hover_data={
        "value": True,
        "f20_39": True,
        "senior65p": True,
        "region": False,
        "ë‹¨ê³„": False,
    },
    color_discrete_sequence=colors,
)
fig_map.update_geos(fitbounds="locations", visible=False)
fig_map.update_layout(
    margin=dict(l=0, r=0, t=0, b=0),
    legend_title_text="ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ ë‹¨ê³„",
    font=dict(family="Pretendard, Noto Sans KR, sans-serif"),
)
st.plotly_chart(fig_map, use_container_width=True)

# ì•ˆë‚´(ê³µì‹ API ì‹¤íŒ¨ ì‹œ)
if "ì˜ˆì‹œ ë°ì´í„°" in st.session_state.get("data_notice", ""):
    st.warning(st.session_state["data_notice"])

# --------------------
# êº¾ì€ì„ ê·¸ë˜í”„(ì—°ë„ë³„ ì¸êµ¬/ì§€ìˆ˜)
# --------------------
st.subheader("ğŸ“ˆ í–‰ì •êµ¬ì—­ë³„ ì—°ë„ë³„ ì¸êµ¬ ë° ì§€ìˆ˜ ì¶”ì´")

df_line = df.copy()
df_line["ì—°ë„"] = df_line["date"].dt.year
df_line["ì‹œë„"] = df_line["group_std"]

col1, col2 = st.columns([2, 1], gap="large")

with col1:
    # ì„ íƒ ì§€ì—­ì˜ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜ ì¶”ì´
    line_df = df_line[df_line["ì‹œë„"].isin(regions_sel)][["ì—°ë„", "ì‹œë„", "value"]].sort_values(["ì‹œë„", "ì—°ë„"])
    fig_line = px.line(
        line_df,
        x="ì—°ë„",
        y="value",
        color="ì‹œë„",
        markers=True,
        labels={"value": "ì¸êµ¬ì†Œë©¸ì§€ìˆ˜", "ì—°ë„": "ì—°ë„", "ì‹œë„": "í–‰ì •êµ¬ì—­"},
    )
    fig_line.update_layout(font=dict(family="Pretendard, Noto Sans KR, sans-serif"))
    st.plotly_chart(fig_line, use_container_width=True)

with col2:
    # ì„ íƒ ì—°ë„ ë¶„í¬ ìš”ì•½
    st.markdown(f"**{year_sel}ë…„ ìš”ì•½(ì‹œë„ë³„)**")
    stat_df = df_year[["region", "value", "f20_39", "senior65p"]].sort_values("value")
    st.dataframe(stat_df.set_index("region"), use_container_width=True, height=420)

# --------------------
# ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# --------------------
st.subheader("â¬‡ï¸ ì „ì²˜ë¦¬ëœ í‘œ ë‹¤ìš´ë¡œë“œ")
download_df = df[["date", "group_std", "f20_39", "senior65p", "value"]].rename(
    columns={"group_std": "group"}
)
csv = download_df.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    "CSV ë‹¤ìš´ë¡œë“œ",
    data=csv,
    file_name="korea_population_extinction_index_by_sido.csv",
    mime="text/csv",
    help="ì „ì²˜ë¦¬ëœ í‘œë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
)

# --------------------
# ì˜¤ë¥˜/ì˜ˆì™¸ í‘œì‹œ (ë°ëª¨)
# --------------------
# API ì—°ê²° ì‹¤íŒ¨ ì—¬ë¶€ë¥¼ ì‚¬ìš©ìê°€ ì•Œ ìˆ˜ ìˆë„ë¡ ë¬¸êµ¬(ì§€ë„/ë°ì´í„° ê°ê°ì—ì„œ í‘œì‹œ)
if 'features' in geojson and len(geojson['features']) <= 1:
    st.info("â€» GeoJSONì„ ì •ìƒì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ì§€ë„ëŠ” ë‹¨ìˆœí•œ ì˜ˆì‹œ í˜•íƒœë¡œ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.")
if "ì „êµ­" in set(df["group"].unique()):
    st.info("â€» ì¸êµ¬ ë°ì´í„°ê°€ ì˜ˆì‹œë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œ API í‚¤/ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

# --------------------
# ì£¼ì„: êµ¬í˜„ íŒ
# --------------------
# 1) MOIS/KOSIS/SGIS API ì—°ê²° ì‹œ:
#    - SGIS(í†µê³„ì§€ë¦¬ì •ë³´ì„œë¹„ìŠ¤) OpenAPI ë¬¸ì„œ: https://sgis.kostat.go.kr/developer/html/openApi/api/data.html
#    - KOSIS OpenAPI: í†µê³„í‘œ IDì™€ íŒŒë¼ë¯¸í„°ë¡œ ì—°ë ¹Â·ì„±ë³„Â·ì§€ì—­ë³„ ì¸êµ¬ ì¶”ì¶œ â†’ 20~39ì„¸ ì—¬ì„± í•©ê³„, 65ì„¸ ì´ìƒ í•©ê³„ ê³„ì‚°
#    - ì‹¤ì œ API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜/Secretsë¡œ ê´€ë¦¬ í›„ requestsë¡œ í˜¸ì¶œ
#
# 2) GeoJSON:
#    - southkorea-maps(KOSTAT 2013) ì‹œë„ GeoJSON:
#      https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2013/json/skorea-provinces-2013-geo.json
#
# 3) ìƒ‰ìƒ 5ë‹¨ê³„(ì—°ë‘~ì§„í•œë¹¨ê°•) ë§ì¶¤ íŒ”ë ˆíŠ¸ ì‚¬ìš©
#
# 4) ë¯¸ë˜ ë°ì´í„° ì œê±°:
#    - ë³¸ ì•±ì€ ë¡œì»¬ ìì • ê¸°ì¤€ ì˜¤ëŠ˜ ì´í›„ì˜ ë°ì´í„°(ì—°ë„í˜• ì‹œê³„ì—´ì—ì„œëŠ” í˜„ì¬ ì—°ë„ë¥¼ ì´ˆê³¼í•˜ëŠ” ì—°ë„)ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
#
# 5) Kaggle ì‚¬ìš© ì‹œ(ìš”ì²­ ì‹œ í™•ì¥):
#    - Codespacesì—ì„œ `pip install kaggle` í›„, ~/.kaggle/kaggle.json(API í† í°) ë°°ì¹˜
#    - ì˜ˆ: `kaggle datasets download -d <owner>/<dataset>` ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
#
# 6) ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ:
#    - ìš”ì²­ì— ë”°ë¼ **ì œê±°**í•˜ì˜€ìŠµë‹ˆë‹¤(ì•± ì‹¤í–‰ ì¤‘ íŒŒì¼ ì—…ë¡œë“œ/í…ìŠ¤íŠ¸ ì…ë ¥ ìš”êµ¬ ì—†ìŒ).
#
# ë.

